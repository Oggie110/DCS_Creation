{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I music2emo 02-10 03:58:55.459 music2emo.py:280] audio file loaded and feature computation success : inference/input/test.mp3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽµ **Music Emotion Recognition Results** ðŸŽµ\n",
      "--------------------------------------------------\n",
      "ðŸŽ­ **Predicted Mood Tags:** ballad, calm, film, hopeful, inspiring, love, meditative, melancholic, relaxing, romantic, sad, soft\n",
      "ðŸ’– **Valence:** 5.42 (Scale: 1-9)\n",
      "âš¡ **Arousal:** 4.16 (Scale: 1-9)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from music2emo import Music2emo\n",
    "\n",
    "input_audio = \"inference/input/test.mp3\"\n",
    "\n",
    "music2emo = Music2emo()\n",
    "output_dic = music2emo.predict(input_audio)\n",
    "\n",
    "valence = output_dic[\"valence\"]\n",
    "arousal = output_dic[\"arousal\"]\n",
    "predicted_moods =output_dic[\"predicted_moods\"]\n",
    "\n",
    "print(\"\\nðŸŽµ **Music Emotion Recognition Results** ðŸŽµ\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"ðŸŽ­ **Predicted Mood Tags:** {', '.join(predicted_moods) if predicted_moods else 'None'}\")\n",
    "print(f\"ðŸ’– **Valence:** {valence:.2f} (Scale: 1-9)\")\n",
    "print(f\"âš¡ **Arousal:** {arousal:.2f} (Scale: 1-9)\")\n",
    "print(\"-\" * 50)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music2emo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
